<div otvl-web>
type: sf-img
src: /assets/images/cabri-tech-ovw/Wild_Baby_Alpine_Chamois_Creux_by_Giles_Laurent.jpg
alt: Article image
title: Wild baby alpine chamois and Swiss alps at Creux du van with sunset colors and snow Photo by Giles Laurent
class_: v-img-header
credit:
  text: Illustration above credit
  href: https://commons.wikimedia.org/wiki/File:006_Wild_Baby_Alpine_Chamois_Creux_du_Van_and_Swiss_Alps_Sunset_colors_Photo_by_Giles_Laurent.jpg
</div>

# Cabri technical overview

<div otvl-web>
type: sf-page-dates
</div>

[Cabri](https://github.com/t-beigbeder/otvl_cabri)
enables fast and secure data synchronization between people, medias and places.

While a [previous article](/blog/cabri-share-conf)
presented its main features from a user's perspective,
this one provides some information on its implementation
to help understanding how efficiency and security are supported.

## Cabri is fast

As seen in the previous article, Cabri enables storing and synchronizing data
either on a local drive or using Cloud Storage,
but in any case providing at the same time full data historization and possible encryption.

Such features require fast access to the actual data and its corresponding metadata:
size, modification time and access rights,
but also the ability to read and write large amount of data either on local devices
or using cloud services over internet.

This section details the main supporting mechanisms.

### Parallel processing

Cabri's most resource intensive use concerns the synchronization of large amount of data.
The following diagram shows the synchronization of a local directory with a local Cabri DSS.

<div otvl-web>
type: sf-img
src: /assets/images/cabri-tech-ovw/parallel.png
alt: Backup files on external drive schema
title: Backup files on external drive
class_: v-img
</div>

When the Cabri DSS is initially empty, all local files will be copied to it,
requiring a large amount of I/O operations,
both for reading the local files content and for writing it to the DSS.
Depending on the storage devices technology, this may be slow or fast, but in the second case,
as most computing hardware is able to parallelize processing,
Cabri takes care of launching several synchronization operations in parallel,
so that the processing is as fast as the technology permits.

To be more explicit:

- a directory's content entries may be processed in parallel
- different subdirectories may be processed in parallel
- a workload reducer controls that system resources usage remains limited, it is configurable
- there is always a significant number of I/O operations pending, so that they start execution
as soon as the corresponding device is ready

The reducer may be limited as much as wanted, and even processing may be fully serialized
in case the system has limited resources.
In the case the target is a slow USB key, the result may even be globally faster than if parallelized.

The following diagram shows the synchronization of a local directory with a Cabri DSS providing cloud storage.
In that case, writing to the DSS requires massive network uploads.

<div otvl-web>
type: sf-img
src: /assets/images/cabri-tech-ovw/parallel-obs.png
alt: Backup files with cloud storage schema
title: Backup files with cloud storage
class_: v-img
</div>

While the Cloud storage providers generally support a large amount of parallel I/O operations,
the limitation will rather come from the available network bandwidth and local system resources.
Using the default reducer configuration will perform fast if the system supports it,
for instance if Cabri is launched as a Cloud service,
but limiting its capacity may be wanted if network errors occur.
For instance, network resources appear more available and efficient on Linux systems than on Windows Home OS,
from my personal experience.

### Other uses of parallelization

Parallel processing is used as well by almost all Cabri features implementation.
Its use appear very valuable in the following situations:

- listing local files or DSS recursively, because it requires many I/O operations,
- computing checksums on a full directory's content, to evaluate the need for synchronization,
- auditing DSS content, rebuilding their index, because it requires a full scan of the DSS

### Flow processing

The underlying encryption technology is [`age`](https://age-encryption.org/)
and it provides the ability to encrypt and decrypt data as a flow.
The following diagram shows data synchronization back and forth
between local files and an encrypted local DSS.

<div otvl-web>
type: sf-img
src: /assets/images/cabri-tech-ovw/flow.png
alt: Flow processing schema
title: Flow processing storage
class_: v-img
</div>

In such a scenario, data sent to the DSS may be written as soon as encrypted data chunks are available.
On the other direction,
data read from the DSS may be written to a local file as soon as decrypted data chunks are available.

### Indexes

Indexing the DSS content metadata is necessary for several reasons:

- DSS metadata on Object Storage cannot be scanned efficiently,
so an index of what is stored in the Cloud must be maintained locally 
- DSS content history remains available, meaning that the full namespace hierarchy of each entry
has to be inspected at access time in order to check if it is visible or hidden
- the same kind of concern applies to the check of access control rules
- so even in the case of a `olf` DSS whose data is accessed locally, the number of I/O required to grant access
may become too important
- the access to encrypted data, which is specifically detailed later in this article

<div otvl-web>
type: sf-img
src: /assets/images/cabri-tech-ovw/index.png
alt: Index of remote metadata schema
title: Index of remote metadata
class_: v-img
</div>

## Cabri is secured

### End-to-end data-level encryption

### Is remote access secure?

### Are indexes secure?

### Distributed meta-data

## Conclusion

Confidentiality of the data processed and stored in unsecured environments
was the first concern when designing the Cabri solution.
I hope this article made you confident with it,
anyway this is open-source, you can verify it!

The cost of security is not necessarily the loss of performance:
for sure encryption and decryption require larger computing power
than bare data transfer, anyway the solution remains as fast as possible
by using parallel processing.

Finally, the data stored on local drives or using cloud storage may be easily
scanned and reindexed after any kind of system crash.
In the case of encrypted data this is obviously only under the condition
you manage the encryption secret keys securely.

## References

- [Cabri project source-code and documentation](https://github.com/t-beigbeder/otvl_cabri)
- [Age](https://age-encryption.org/) - A simple, modern and secure encryption tool
